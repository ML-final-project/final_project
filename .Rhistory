demand_C <- mutate(demand_C,Quantity_2_t=ifelse(Price > 250, Quantity_2_m+(300-182), Quantity_2_d))
write.csv(demand_C, "demand_C.csv")
setwd("~/Desktop/Regulate Firms/CSG")
write.csv(demand_C, "demand_C.csv")
library(readr)
library(tidyverse)
library(snakecase)
library(lubridate)
library(ggplot2)
library(gridExtra)
setwd("~/Documents/GitHub/final_project/analysis")
pm25_chicago <- read_csv("~/Documents/GitHub/final_project/data/pm25/pm25_chicago_2010.csv") %>%
set_names(to_snake_case(colnames(.))) %>%
mutate(date = mdy(date))
#bar plot of the avg pm25 overy the year at ea site
pm25_chicago %>%
group_by(site_name)%>%
summarize(mean_pm25 = mean(daily_mean_pm_2_5_concentration)) %>%
ggplot(aes(x = site_name, y =  mean_pm25))+
geom_bar(stat = "identity")
#line plot of avg monthly pm25 for a single station
plot_month_pm25 <- function(xi, s_name){
one_site <- pm25_chicago%>%
filter(site_id == xi)
one_site %>%
group_by(month=floor_date(date, "month")) %>%
#https://ro-che.info/articles/2017-02-22-group_by_month_r
summarize(mean_pm25 = mean(daily_mean_pm_2_5_concentration)) %>%
ggplot() +
geom_line(aes(x=month, y = mean_pm25))+
labs(title = s_name)
}
p1 <- plot_month_pm25(170310052,"MAYFAIR PUMP STATION")
p2<- plot_month_pm25(170310057, "SPRINGFIELD PUMP STATION")
p3 <- plot_month_pm25(170311016, "VILLAGE HALL")
p4 <- plot_month_pm25(181270024, "Ogden Dunes- Water Treatment Plant")
grid.arrange(p1,p2,p3,p4)
View(p1)
library(rprojroot)
make_path <- is_git_root$make_fix_file()
config <- yaml.load_file(make_path("analysis/config.yml"))
out_path <- make_path(config$build_path)
noaa <- read_csv(make_path(config$data_path$noaa,
"Chicago2010Data.csv")) %>%
set_names(to_snake_case(colnames(.))) %>%
st_as_sf(coords = c("longitude", "latitude"),
crs = 4326, remove = FALSE) %>%
st_transform("+proj=utm +zone=42N +datum=WGS84 +units=km") #%>%
setwd("~/final_project/")
setwd("~/final_project/")
setwd("~/Documents/GitHub/final_project/analysis/source")
setwd("~/final_project/")
View(pm25_chicago)
grid.arrange(p1,p2,p3,p4)
out_path <- make_path(config$build_path)
ggsave("seasonality_top_4_pm25_stations.png", plot = last_plot(), path = out_path)
plot <- grid.arrange(p1,p2,p3,p4)
ggsave("seasonality_top_4_pm25_stations.png", plot = last_plot(), path = out_path)
plot <- grid.arrange(p1,p2,p3,p4)
ggsave("seasonality_top_4_pm25_stations.png", plot, path = out_path)
plot_list <- c()
for (i in pm25_chicago$site_id){
plot_i <- plot_month_pm25(i, i)
append(plot_list, plot_i)
}
for (i in pm25_chicago$site_id){
print(i)
}
site_ids <- unique(pm25_chicago$site_id)
for (i insite_ids){
print(i)
}
for (i in site_ids){
print(i)
}
for (i in site_ids){
plot_i <- plot_month_pm25(i, i)
append(plot_list, plot_i)
}
grid.arrange(plot_list)
grid.arrange(plot_list[1])
View(p3)
site_ids <- unique(pm25_chicago$site_id)
plot_list <- c()
for (i in site_ids){
plot_i <- plot_month_pm25(i, i)
append(plot_list, plot_i)
}
View(plot_i)
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Documents/GitHub/problem-set-2")
library(readr)
library(rcfss)
set.seed(1234)
nes2008_df <- read_csv("nes2008.csv")
regn_model <- glm(biden~female+age+educ+dem+rep, data = nes2008_df)
summary(regn_model)
(mse <- augment(regn_model, newdata = nes2008_df) %>%
mse(truth = biden, estimate = .fitted))
regn_model <- glm(biden~female+age+educ+dem+rep, data = nes2008_df)
summary(regn_model)
regn_model$coefficients
regn_model$coefficients[1]
?analysis
boot_mean <- function(data, i) {
d <- data[i] # allows boot to select sample
return(mean(d))
}
# Set number of bootstrap replications
B=10000
# bootstrapping with B replications.
boot.mean <- boot(data=nes2008_df, statistic=boot_mean, B)
library(boot)
# bootstrapping with B replications.
boot.mean <- boot(data=nes2008_df, statistic=boot_mean, B)
boot_mean <- function(data) {
#d <- data[i] # allows boot to select sample
return(mean(d))
}
# bootstrapping with B replications.
boot.mean <- boot(data=nes2008_df, statistic=boot_mean, B)
# bootstrapping with B replications.
boot.mean <- boot(data=nes2008_df$biden, statistic=boot_mean, B)
test <- nes2008_df$biden
# bootstrapping with B replications.
boot.mean <- boot(data=test, statistic=boot_mean, B)
regn_model <- lm(biden ~ female + age + educ + dem + rep, data = nes)
regn_model <- lm(biden ~ female + age + educ + dem + rep, data = nes2008_df)
tidy(regn_model)
library(tidyr)
tidy(regn_model)
library(tidyverse)
tidy(regn_model)
library(broom)
tidy(regn_model)
# bootstrapped estimates of the parameter estimates and standard errors
lm_coefs <- function(nes, ...) {
## use `analysis` or `as.data.frame` to get the analysis data
mod <- lm(..., data = analysis(nes))
tidy(mod)
}
biden_boot <- nes %>%
bootstraps(1000) %>%
mutate(coef = map(splits, lm_coefs, as.formula(biden ~ female + age + educ + dem + rep)))
biden_boot <- nes2008_df %>%
bootstraps(1000) %>%
mutate(coef = map(splits, lm_coefs, as.formula(biden ~ female + age + educ + dem + rep)))
biden_boot <- nes2008_df %>%
bootstraps(1000) %>%
mutate(coef = map(splits, lm_coefs, as.formula(biden ~ female + age + educ + dem + rep)))
library(broom)
biden_boot <- nes2008_df %>%
bootstraps(1000) %>%
mutate(coef = map(splits, lm_coefs, as.formula(biden ~ female + age + educ + dem + rep)))
# bootstrapped estimates of the parameter estimates and standard errors
lm_coefs <- function(nes, ...) {
## use `analysis` or `as.data.frame` to get the analysis data
mod <- lm(..., data = analysis(nes))
#tidy(mod)
}
biden_boot <- nes2008_df %>%
bootstraps(1000) %>%
mutate(coef = map(splits, lm_coefs, as.formula(biden ~ female + age + educ + dem + rep)))
biden_boot %>%
unnest(coef) %>%
group_by(term) %>%
summarize(.estimate = mean(estimate),
.se = sd(estimate, na.rm = TRUE))
coef
biden_boot %>%
unnest(coef) %>%
group_by(term) %>%
summarize(.estimate = mean(estimate),
.se = sd(estimate, na.rm = TRUE))
library(broom)
tidy(regn_model)
summary(regn_model)$coefficients
summary(regn_model)$coefficients
# bootstrapped estimates of the parameter estimates and standard errors
lm_coefs <- function(nes, ...) {
## use `analysis` or `as.data.frame` to get the analysis data
mod <- lm(..., data = analysis(nes))
summary(mod)$coefficients
}
biden_boot <- nes2008_df %>%
bootstraps(1000) %>%
mutate(coef = map(splits, lm_coefs, as.formula(biden ~ female + age + educ + dem + rep)))
biden_boot %>%
unnest(coef) %>%
group_by(term) %>%
summarize(.estimate = mean(estimate),
.se = sd(estimate, na.rm = TRUE))
unnest(coef)
mean(biden_boot$mean)
View(biden_boot)
biden_boot <- nes2008_df %>%
bootstraps(1000) %>%
mutate(coef = map(splits, lm_coefs, as.formula(biden ~ female + age + educ + dem + rep)))
View(biden_boot)
biden_bood$coef[1]
biden_boot$coef[1]
biden_boot$coef[1][1]
biden_boot$coef[1][2]
biden_boot$coef[2]
biden_boot$coef[2]$coefficients
# bootstrapped estimates of the parameter estimates and standard errors
lm_coefs <- function(nes2008_df, ...) {
## use `analysis` or `as.data.frame` to get the analysis data
mod <- lm(..., data = analysis(nes))
summary(mod)$coefficients
}
biden_boot <- nes2008_df %>%
bootstraps(1000) %>%
mutate(coef = map(splits, lm_coefs, as.formula(biden ~ female + age + educ + dem + rep)))
# bootstrapped estimates of the parameter estimates and standard errors
lm_coefs <- function(nes2008_df, ...) {
## use `analysis` or `as.data.frame` to get the analysis data
mod <- lm(..., data = analysis(nes))
summary(mod)$coefficients
}
biden_boot <- nes2008_df %>%
bootstraps(1000) %>%
mutate(coef = map(splits, lm_coefs, as.formula(biden ~ female + age + educ + dem + rep)))
regn_model <- lmg(biden ~ female + age + educ + dem + rep, data = nes2008_df)
regn_model <- glm(biden ~ female + age + educ + dem + rep, data = nes2008_df)
summary(regn_model)$coefficients
# bootstrapped estimates of the parameter estimates and standard errors
lm_coefs <- function(nes2008_df, ...) {
## use `analysis` or `as.data.frame` to get the analysis data
mod <- lm(..., data = analysis(nes))
summary(mod)$coefficients
}
biden_boot <- nes2008_df %>%
bootstraps(1000) %>%
mutate(coef = map(splits, lm_coefs, as.formula(biden ~ female + age + educ + dem + rep)))
# bootstrapped estimates of the parameter estimates and standard errors
lm_coefs <- function(nes2008_df, ...) {
## use `analysis` or `as.data.frame` to get the analysis data
mod <- lm(..., data = analysis(nes))
#summary(mod)$coefficients
}
mean(mse_lise)
#Rei: replicate function makes doing it much easier than like looping
#source https://www.datamentor.io/r-programming/repeat-loop/
x <- 1
mse_list <- c()
repeat{
nes_split <- initial_split(data = nes2008_df,
prop = 0.5) #split the data in half
nes_train <- training(nes_split) #random subsample to train
nes_test <- testing(nes_split)
#Fit the linear regression model using only the training observations.
nes_lm <- glm(biden~female+age+educ+dem+rep, data = nes_train) #fit model on training   data
mse <- augment(nes_lm, newdata = nes_test) %>%
mse(truth = biden, estimate = .fitted)%>%
select(.estimate)%>%
as.numeric()
mse_list <- append(mse_list,mse)
x= x+1
if (x == 1000){
break
}
}
mean(mse_lise)
mean(mse_list)
#summary(regn_model)$coefficients
tidy(regn_model)
regn_model <- lm(biden ~ female + age + educ + dem + rep, data = nes2008_df)
#summary(regn_model)$coefficients
tidy(regn_model)
#summary(regn_model)$coefficients
analysis((regn_model)
regn_model <- glm(biden ~ female + age + educ + dem + rep, data = nes2008_df)
mean(nes2008_df$biden)
var(nes2008_df$biden)
max(nes2008_df$biden)
var(nes2008_df$biden)
min(nes2008_df$biden)
mean(nes2008_df$biden)
#summary(regn_model)$coefficients
analysis((regn_model)
#summary(regn_model)$coefficients
analysis(regn_model)
?analysis
# bootstrapped estimates of the parameter estimates and standard errors
lm_coefs <- function(nes2008_df, ...) {
## use `analysis` or `as.data.frame` to get the analysis data
mod <- lm(..., data = analysis(nes))
#summary(mod)$coefficients
analysisi(mod)
}
biden_boot <- nes2008_df %>%
bootstraps(1000) %>%
mutate(coef = map(splits, lm_coefs, as.formula(biden ~ female + age + educ + dem + rep)))
##clear working memory
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Documents/GitHub/problem-set-2")
library(readr)
library(rcfss)
library(boot)
library(tidyverse)
library(broom)
set.seed(1234)
nes2008_df <- read_csv("nes2008.csv")
regn_model <- glm(biden~female+age+educ+dem+rep, data = nes2008_df)
summary(regn_model)
(mse <- augment(regn_model, newdata = nes2008_df) %>%
mse(truth = biden, estimate = .fitted))
max(nes2008_df$biden)
min(nes2008_df$biden)
var(nes2008_df$biden)
mean(nes2008_df$biden)
#Split the sample set into a training set (50%) and a holdout set (50%). Be sure to set your seed prior to this part of your code to guarantee reproducibility of results.
nes_split <- initial_split(data = nes2008_df,
prop = 0.5) #split the data in half
nes_train <- training(nes_split) #random subsample to train
nes_test <- testing(nes_split)
#Fit the linear regression model using only the training observations.
nes_lm <- glm(biden~female+age+educ+dem+rep, data = nes_train) #fit model on training data
#(train_mse <- augment(nes_lm, newdata = nes_train) %>%
#  mse(truth = biden, estimate = .fitted))
#Calculate the MSE using only the test set observations.
(test_mse <- augment(nes_lm, newdata = nes_test) %>%
mse(truth = biden, estimate = .fitted))
#Rei: replicate function makes doing it much easier than like looping
#source https://www.datamentor.io/r-programming/repeat-loop/
x <- 1
mse_list <- c()
repeat{
nes_split <- initial_split(data = nes2008_df,
prop = 0.5) #split the data in half
nes_train <- training(nes_split) #random subsample to train
nes_test <- testing(nes_split)
#Fit the linear regression model using only the training observations.
nes_lm <- glm(biden~female+age+educ+dem+rep, data = nes_train) #fit model on training   data
mse <- augment(nes_lm, newdata = nes_test) %>%
mse(truth = biden, estimate = .fitted)%>%
select(.estimate)%>%
as.numeric()
mse_list <- append(mse_list,mse)
x= x+1
if (x == 1000){
break
}
}
mean(mse_list)
data <- data.frame(mse = mse_list)
ggplot(data, aes(x = mse))+
geom_histogram(binwidth = 1, alpha = 0.75)
regn_model <- glm(biden ~ female + age + educ + dem + rep, data = nes2008_df)
#summary(regn_model)$coefficients
analysis(regn_model)
# bootstrapped estimates of the parameter estimates and standard errors
lm_coefs <- function(nes2008_df, ...) {
## use `analysis` or `as.data.frame` to get the analysis data
mod <- lm(..., data = analysis(nes2008_df))
summary(mod)$coefficients
#analysisi(mod)
}
biden_boot <- nes2008_df %>%
bootstraps(1000) %>%
mutate(coef = map(splits, lm_coefs, as.formula(biden ~ female + age + educ + dem + rep)))
biden_boot %>%
unnest(coef) %>%
group_by(term) %>%
summarize(.estimate = mean(estimate),
.se = sd(estimate, na.rm = TRUE))
#analysisi(mod)
tidy(mod)
tidy(mod)
library(ISLR)
tidy(mod)
tidy(auto_lm) #another way to show regn output
#analysisi(mod)
augment(mod)
regn_model <- lm(biden ~ female + age + educ + dem + rep, data = nes2008_df)
tidy(regn_model)
library(tidyverse)
library(ISLR) #to load the data
library(broom)
library(rsample)
library(rcfss)
library(yardstick)
#devtools:: install_github("uc-cfss/rcfss") #how install for stuff not on cran
Auto <- as_tibble(Auto)
set.seed(1234)
auto_split <- initial_split(data = Auto,
prop = 0.5) #split the data in half
auto_train <- training(auto_split) #random subsample to train
auto_test <- testing(auto_split)
library(ISLR)
Auto <- as_tibble(Auto)
skimr::skim(Auto) #nicer regn output
library(ISLR)
Auto <- as_tibble(Auto)
#skimr::skim(Auto) #nicer regn output
# plot the data and model
ggplot(Auto, aes(horsepower, mpg)) +
geom_point() +
geom_smooth(method = "lm") #put linear fit line over it! can do lowess instead
# traditional parameter estimates and standard errors
auto_lm <- lm(mpg ~ poly(horsepower, 1, raw = TRUE), data = Auto)
tidy(auto_lm) #another way to show regn output
regn_model <- lm(biden ~ female + age + educ + dem + rep, data = nes2008_df)
summary(regn_model)
# bootstrapped estimates of the parameter estimates and standard errors
lm_coefs <- function(nes2008_df, ...) {
## use `analysis` or `as.data.frame` to get the analysis data
mod <- lm(..., data = analysis(nes2008_df))
#tidy(mod)
summary(mod)
}
biden_boot <- nes2008_df %>%
bootstraps(1000) %>%
mutate(coef = map(splits, lm_coefs, as.formula(biden ~ female + age + educ + dem + rep)))
biden_boot$coef[2]
unnest(coef)
biden_boot %>%
unnest(coef) %>%
group_by(term) %>%
summarize(.estimate = mean(estimate),
.se = sd(estimate, na.rm = TRUE))
biden_boot %>%
#unnest(coef) %>%
#group_by(term) %>%
summarize(.estimate = mean(estimate),
.se = sd(estimate, na.rm = TRUE))
View(biden_boot)
biden_boot$coef[2]
summarise(biden_boot$coef)
mean(biden_boot$coef)
biden_boot$coef
unnest(biden_boot$coef)
biden_boot$coef[[1][1]]
#tidy(mod)
summarize(mod)
tidy(mod)
tidy(regn_model)
broom::tidy()
tidy(regn_model)
# bootstrapped estimates of the parameter estimates and standard errors
lm_coefs <- function(splits, ...) {
## use `analysis` or `as.data.frame` to get the analysis data
mod <- lm(..., data = analysis(splits))
#tidy(mod)
summary(mod)
}
biden_boot <- nes2008_df %>%
bootstraps(1000) %>%
mutate(coef = map(splits, lm_coefs, as.formula(biden ~ female + age + educ + dem + rep)))
biden_boot %>%
unnest(coef) %>%
group_by(term) %>%
summarize(.estimate = mean(estimate),
.se = sd(estimate, na.rm = TRUE))
remove.packages("broom")
install.packages("broom")
library(yaml)
library(rprojroot)
library(tidyverse)
library(lubridate)
library(snakecase)
library(sf)
setwd("~/final_project/")
make_path <- is_git_root$make_fix_file()
config <- yaml.load_file(make_path("analysis/config.yml"))
out_path <- make_path(config$build_path)
data_out <- make_path(config$data_path$merge)
source(str_c(config$group_code, "prelim.R"))
temp <- read_csv(make_path(config$data_path$noaa,
"Chicago2010Daily.csv"))
View(temp)
temp <- read_csv(make_path(config$data_path$noaa,
"Chicago2010Daily.csv")) %>%
mutate_all(~na_if(., -9999))
View(temp)
temp <- read_csv(make_path(config$data_path$noaa,
"Chicago2010Daily.csv")) %>%
mutate_all(~na_if(., -9999)) %>%
na.omit()
noaa <- read_csv(make_path(config$data_path$noaa,
"Mass2010Normal.csv")) %>%
set_names(to_snake_case(colnames(.))) %>%
select(station_name,
date,
elevation,
latitude,
longitude,
contains("normal")) %>%
na_if(-9999) %>%
na.omit() %>%
mutate(date = ymd(date)) %>%
mutate(state = case_when(str_detect(station_name, "CA") ~ "CA",
str_detect(station_name, "IL") ~ "IL",
str_detect(station_name, "AK") ~ "AK",
str_detect(station_name, "CO") ~ "CO",
str_detect(station_name, "FL") ~ "FL")) %>%
st_as_sf(coords = c("longitude", "latitude"),
crs = 4326, remove = FALSE) %>%
st_transform("+proj=utm +zone=42N +datum=WGS84 +units=km")
11920 - 1103
View(temp)
View(temp)
View(noaa)
temp <- read_csv(make_path(config$data_path$noaa,
"Chicago2010Daily.csv")) #%>%
temp <- read_csv(make_path(config$data_path$noaa,
"Chicago2010Daily.csv")) %>%
mutate_all(~na_if(., -9999)) %>%
na.omit()
View(temp)
